{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"C:/Machine Learning/Hackathons\\Kaggle/Santander Customer Transaction Prediction/train.csv\")\n",
    "test = pd.read_csv(\"C:/Machine Learning/Hackathons\\Kaggle/Santander Customer Transaction Prediction/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[:,\"var_0\":\"var_199\"].loc[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby([\"target\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.target.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_count(df,threshold= 0):\n",
    "    \"\"\"\n",
    "    #input: \n",
    "        df = dataframe for which we have to calculate the missing counts\n",
    "        threshold = threshold for the missing count\n",
    "    #return:\n",
    "        columns and their missing count percentage\"\"\"\n",
    "    missing  = df.isnull().sum().sort_values(ascending = False)\n",
    "    return (missing[missing>len(df)*(threshold/100)]/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_count(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby(\"target\").count()[\"ID_code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_GS = {\"max_depth\": [2,4,6,8,10,12]\n",
    "        ,\"max_features\" : [\"sqrt\", \"log2\"]\n",
    "        ,\"criterion\":[\"gini\",\"entropy\"]\n",
    "        ,\"min_samples_leaf\":[2,4,8,16,32]\n",
    "        #,\"max_leaf_nodes\":[2,4,8,16,32] \n",
    "        ,\"class_weight\":[\"balanced\"]\n",
    "        ,\"max_leaf_nodes\":[2,4,8,16,32]\n",
    "       }\n",
    "para_lgbm = {\"max_depth\": [6,8]\n",
    "        ,\"num_leaves\":[16,64,32]\n",
    "       }\n",
    "model_Performance =[]\n",
    "#for train_index , test_index in skf.split(train.loc[:,\"var_0\":\"var_199\"], train[\"target\"]):\n",
    "trainx_outer, testx_outer,trainy_outer, testy_outer = train_test_split(train.loc[:,\"var_0\":\"var_199\"],\n",
    "                                                                       train[\"target\"],test_size=0.30,random_state =10,\n",
    "                                                                       stratify = train[\"target\"])\n",
    "model_perf = {}\n",
    "#trainx_outer, testx_outer = train.loc[:,\"var_0\":\"var_199\"].loc[train_index], train.loc[:,\"var_0\":\"var_199\"].loc[test_index]\n",
    "#trainy_outer, testy_outer = train[\"target\"].loc[train_index], train[\"target\"].loc[test_index]\n",
    "print(trainx_outer.shape, testx_outer.shape, testy_outer.shape, testy_outer.shape)\n",
    "gs= GridSearchCV(estimator=lgbm, cv=5, param_grid=para_lgbm,n_jobs=4, scoring=\"roc_auc\",return_train_score=True)\n",
    "print(gs)\n",
    "gs.fit(trainx_outer,trainy_outer)\n",
    "pre = gs.predict(testx_outer)\n",
    "test_score = roc_auc_score(testy_outer,pre)\n",
    "model_perf.update({\"best_estimator_\":gs.best_estimator_})\n",
    "model_perf.update({\"best_score_\" : gs.best_score_})\n",
    "model_perf.update({\"best_params_\" : gs.best_params_})\n",
    "model_perf.update({\"test_score\" :   test_score})\n",
    "#model_perf.update({\"gs.cv_results_\" : gs.cv_results_})\n",
    "\n",
    "model_Performance.append(model_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_RS =     {\"criterion\": [\"entropy\",\"gini\"],\n",
    "               #\"splitter\":[\"best\",\"random\"],\n",
    "               \"max_depth\": randint(1,12),\n",
    "               \"min_samples_split\":randint(250,425),\n",
    "               \"min_samples_leaf\": randint(2, 50),\n",
    "               #\"min_weight_fraction_leaf\":[],\n",
    "               \"max_features\": [\"log2\", \"sqrt\"],\n",
    "               \"class_weight\":['balanced'],\n",
    "               \"max_leaf_nodes\":randint(10,30),\n",
    "               \"min_impurity_decrease\":[0,.01,.001,.2,.7],\n",
    "               \"n_estimators\":randint(700,1500)\n",
    "              }\n",
    "rf = RandomForestClassifier()\n",
    "model_Performance =[]\n",
    "#for train_index , test_index in skf.split(train.loc[:,\"var_0\":\"var_199\"], train[\"target\"]):\n",
    "trainx_outer, testx_outer,trainy_outer, testy_outer = train_test_split(train.loc[:,\"var_0\":\"var_199\"],\n",
    "                                                                       train[\"target\"],test_size=0.30,random_state =10,\n",
    "                                                                       stratify = train[\"target\"])\n",
    "model_perf = {}\n",
    "#trainx_outer, testx_outer = train.loc[:,\"var_0\":\"var_199\"].loc[train_index], train.loc[:,\"var_0\":\"var_199\"].loc[test_index]\n",
    "#trainy_outer, testy_outer = train[\"target\"].loc[train_index], train[\"target\"].loc[test_index]\n",
    "print(trainx_outer.shape, testx_outer.shape, testy_outer.shape, testy_outer.shape)\n",
    "gs= RandomizedSearchCV(estimator=rf, cv=5, param_distributions=para_RS,\n",
    "                       n_jobs=4,n_iter =1, scoring=\"roc_auc\",return_train_score=True)\n",
    "gs.fit(trainx_outer,trainy_outer)\n",
    "pre = gs.predict(testx_outer)\n",
    "test_score = roc_auc_score(testy_outer,pre)\n",
    "model_perf.update({\"best_estimator_\":gs.best_estimator_})\n",
    "model_perf.update({\"best_score_\" : gs.best_score_})\n",
    "model_perf.update({\"best_params_\" : gs.best_params_})\n",
    "model_perf.update({\"test_score\" :   test_score})\n",
    "#model_perf.update({\"gs.cv_results_\" : gs.cv_results_})\n",
    "\n",
    "model_Performance.append(model_perf)\n",
    "model_Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight as t\n",
    "v = t(class_weight=\"balanced\",y=train[\"target\"])\n",
    "v[1:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier ,ExtraTreesClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "import lightgbm\n",
    "import xgboost\n",
    "rf = RandomForestClassifier()\n",
    "#from sklearn.preprocessing import \n",
    "dt = DecisionTreeClassifier()\n",
    "et = ExtraTreesClassifier()\n",
    "dtt = DecisionTreeClassifier()\n",
    "ab =  AdaBoostClassifier(base_estimator=dtt)\n",
    "gb= GradientBoostingClassifier()\n",
    "lr = LogisticRegression()\n",
    "lgbm = lightgbm.LGBMClassifier()\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "QDA = QuadraticDiscriminantAnalysis()\n",
    "xgb = xgboost.XGBClassifier(eval_metric = \"auc\")\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform(.1,.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage='auto',\n",
      "              solver='lsqr', store_covariance=False, tol=0.0001)\n",
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage='auto',\n",
      "              solver='lsqr', store_covariance=False, tol=0.0001)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6331702346590186, 2.275010585784912)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx_outer, testx_outer,trainy_outer, testy_outer = train_test_split(train.loc[:,\"var_0\":\"var_199\"],\n",
    "                                                                       train[\"target\"],test_size=0.30,random_state =10,\n",
    "                                                                       stratify = train[\"target\"])\n",
    "#gbb = GradientBoostingClassifier(n_estimators=40,max_depth=7 )\n",
    "#gbb  = LogisticRegressionCV(class_weight = \"balanced\",refit= True, random_state = 96)\n",
    "#gbb = ExtraTreesClassifier(class_weight='balanced',criterion= 'gini',max_depth= 6,\n",
    "#                          max_features= 'log2',max_leaf_nodes= 29,min_impurity_decrease= 0\n",
    "#                          ,min_samples_leaf= 18,min_samples_split= 416,n_estimators= 287)\n",
    "#gbb = xgboost.XGBClassifier(objective=\"binary:logistic\", random_state=113,eval_metric = \"auc\")\n",
    "gbb = LinearDiscriminantAnalysis(shrinkage=\"auto\",solver=\"lsqr\")\n",
    "#gbb = QuadraticDiscriminantAnalysis()\n",
    "print(gbb)\n",
    "tick = time.time()\n",
    "gbb.fit(trainx_outer,trainy_outer)\n",
    "tock = time.time()\n",
    "print(gbb)\n",
    "pred = gbb.predict(testx_outer)\n",
    "test_score_rs = roc_auc_score(testy_outer,pred)\n",
    "total_time =  tock - tick\n",
    "test_score_rs, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbb.n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_GS = {\"max_depth\": [10,12,14,18,22]\n",
    "            ,\"max_features\" : [\"sqrt\", \"log2\"]\n",
    "            ,\"criterion\":[\"gini\",\"entropy\"]\n",
    "            ,\"min_samples_leaf\":[2,4,8,16,32]\n",
    "            ,\"max_leaf_nodes\":[2,4,8,16,32] \n",
    "            ,\"class_weight\":[\"balanced\"]\n",
    "            ,\"max_leaf_nodes\":[2,4,8,16,32]\n",
    "           }\n",
    "\n",
    "\n",
    "para_RS_RF =   {\"criterion\": [\"entropy\",\"gini\"],\n",
    "               #\"splitter\":[\"best\",\"random\"],\n",
    "               \"max_depth\": randint(1,12),\n",
    "               \"min_samples_split\":randint(250,425),\n",
    "               \"min_samples_leaf\": randint(2, 50),\n",
    "               #\"min_weight_fraction_leaf\":[],\n",
    "               \"max_features\": [\"log2\", \"sqrt\"],\n",
    "               \"class_weight\":['balanced'],\n",
    "               \"max_leaf_nodes\":randint(10,30),\n",
    "               \"min_impurity_decrease\":[0,.01,.001,.2,.7],\n",
    "               \"n_estimators\":randint(140,500)\n",
    "              }\n",
    "\n",
    "para_RS_AB =  {\"base_estimator__criterion\": [\"entropy\",\"gini\"],\n",
    "               #\"splitter\":[\"best\",\"random\"],\n",
    "               \"base_estimator__max_depth\": randint(1,12),\n",
    "               \"base_estimator__min_samples_split\":randint(250,425),\n",
    "               \"base_estimator__min_samples_leaf\": randint(2, 50),\n",
    "               #\"min_weight_fraction_leaf\":[],\n",
    "               \"base_estimator__max_features\": [\"log2\", \"sqrt\"],\n",
    "               \"base_estimator__class_weight\":['balanced'],\n",
    "               \"base_estimator__max_leaf_nodes\":randint(10,30),\n",
    "               \"base_estimator__min_impurity_decrease\":[0,.01,.001,.2,.7],\n",
    "               \"n_estimators\":randint(50,200),\n",
    "               \"algorithm\": [\"SAMME.R\"]\n",
    "               }\n",
    "\n",
    "para_RS_GB =   {\"loss\":[\"deviance\",\"exponential\"],\n",
    "                \"learning_rate\":[.1,.01,.001,.5,.05,.005],\n",
    "                \"criterion\": [\"friedman_mse\",\"mse\",\"mae\"],\n",
    "               #\"splitter\":[\"best\",\"random\"],\n",
    "               \"max_depth\": randint(1,12),\n",
    "               \"min_samples_split\":randint(200,425),\n",
    "               \"min_samples_leaf\": randint(2, 50),\n",
    "               #\"min_weight_fraction_leaf\":[],\n",
    "               \"max_features\": [\"log2\", \"sqrt\"],\n",
    "               \"max_leaf_nodes\":randint(10,30),\n",
    "               \"min_impurity_decrease\":[0,.01,.001,.2,.7],\n",
    "               \"n_estimators\":randint(10,30),\n",
    "               #\"warm_start\" : [True],\n",
    "               #\"verbose\":[1]\n",
    "               #\"n_iter_no_change\" :[1]\n",
    "                \n",
    "              }\n",
    "\n",
    "para_LR = {\"penalty\": [\"l2\",\"l1\"],\n",
    "          #,\"solver\" : [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
    "           # ,\"C\":[1,0.5,2,2.5],\n",
    "           \"class_weight\":[\"balanced\"]\n",
    "           }\n",
    "para_XGB = {\"max_depth\": randint(1,12),\n",
    "            \"learning_rate\":[.1,.01,.001,.5,.05,.005],\n",
    "            \"n_estimators\":randint(50,250),\n",
    "            \"booster\" :[\"gbtree\", \"gblinear\",\"dart\"],\n",
    "            \"gamma\":uniform(.01,.001),\n",
    "            \"reg_lambda\": uniform(1.0, .001),\n",
    "            \"scale_pos_weight\":[8,9,10]\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_parameters(model, X, Y,scoring, grid_para,random_para,grid_search= False, randomsearch = False):\n",
    "    \n",
    "    trainx_outer, testx_outer,trainy_outer, testy_outer = train_test_split(X, Y,test_size=0.30,random_state =10,\n",
    "                                                                               stratify = Y)\n",
    "    print(trainx_outer.shape, testx_outer.shape, testy_outer.shape, testy_outer.shape)\n",
    "    model_Performance_gs =[]\n",
    "    model_Performance_rs =[]\n",
    "    if (grid_search== True):\n",
    "        tick = time.time()\n",
    "        model_perf_gs = {}\n",
    "        print(\"Grid_Search_Begin\")\n",
    "\n",
    "        gs= GridSearchCV(estimator=model, cv=5, param_grid=grid_para,n_jobs=4, scoring=scoring,\n",
    "                         return_train_score=True,random_state = 112)\n",
    "        gs.fit(trainx_outer,trainy_outer)\n",
    "        pre = gs.predict(testx_outer)\n",
    "        test_score = roc_auc_score(testy_outer,pre)\n",
    "        model_perf_gs.update({\"best_estimator_\":gs.best_estimator_})\n",
    "        model_perf_gs.update({\"best_score_\" : gs.best_score_})\n",
    "        model_perf_gs.update({\"best_params_\" : gs.best_params_})\n",
    "        model_perf_gs.update({\"test_score\" :   test_score})\n",
    "        model_perf_gs.update({\"gs.cv_results_\" : gs.cv_results_})\n",
    "        tock = time.time()\n",
    "        model_perf_gs.update({\"time to execute\" :   tock-tick})\n",
    "        model_Performance_gs.append(model_perf_gs)\n",
    "        print(\"Grid_Search_End\")\n",
    "       \n",
    "    if (randomsearch == True):\n",
    "        tick = time.time()\n",
    "        model_perf_rs = {}\n",
    "        print(\"Random_Search_begin\")\n",
    "        rs= RandomizedSearchCV(estimator=model, cv=5, param_distributions=random_para,\n",
    "                               n_jobs=3,n_iter =50, scoring=scoring,return_train_score=True,random_state = 111)\n",
    "        print(\"rs\", model)\n",
    "        rs.fit(trainx_outer,trainy_outer)\n",
    "        pred = rs.predict(testx_outer)\n",
    "        test_score_rs = roc_auc_score(testy_outer,pred)\n",
    "        model_perf_rs.update({\"best_estimator_\":rs.best_estimator_})\n",
    "        model_perf_rs.update({\"best_score_\" : rs.best_score_})\n",
    "        model_perf_rs.update({\"best_params_\" : rs.best_params_})\n",
    "        model_perf_rs.update({\"test_score\" :test_score_rs})\n",
    "        #model_perf_rs.update({\"gs.cv_results_\" : rs.cv_results_})\n",
    "        tock = time.time()\n",
    "        #print(\"cccccccccccc>>>\",rs.cv_results_ )\n",
    "        model_perf_rs.update({\"time to execute\" :   tock-tick})\n",
    "        model_Performance_rs.append(model_perf_rs)\n",
    "        \n",
    "        print(\"Random_Search_end\")\n",
    "        \n",
    "    return (model_Performance_gs,model_Performance_rs, rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_results , random_results,rs_handle = search_parameters(xgb,train.loc[:,\"var_0\":\"var_199\"], \n",
    "                                                            train[\"target\"],\"roc_auc\", \n",
    "                                                            para_GS,para_XGB,grid_search=False, \n",
    "                                                            randomsearch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_handle.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'best_score_': 0.8159243463116315,\n",
    "  'best_params_': {'booster': 'gbtree',\n",
    "   'gamma': 0.01012075778222881,\n",
    "   'learning_rate': 0.05,\n",
    "   'max_depth': 7,\n",
    "   'n_estimators': 69,\n",
    "   'reg_lambda': 1.000769262472523,\n",
    "   'scale_pos_weight': 8},\n",
    "  'test_score': 0.7139959724597189,\n",
    "  'time to execute': 5346.696860074997}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_values = pd.DataFrame(columns=[\"Logit_reg\"],\n",
    "                               data =rs_handle.predict_proba(test.loc[:,\"var_0\":\"var_199\"])[:,1],\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_values[\"ExtraTree\"] = gbb.predict_proba(test.loc[:,\"var_0\":\"var_199\"])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, hp, tpe, Trials, space_eval, partial\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx_outer, testx_outer,trainy_outer, testy_outer = train_test_split(train.loc[:,\"var_0\":\"var_199\"],\n",
    "                                                                       train[\"target\"],test_size=0.30,random_state =10,\n",
    "                                                                       stratify = train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower =  1\n",
    "para_BS =     {\"max_depth\": 1 + hp.randint('max_depth', 50-2),\n",
    "              \"max_features\": hp.choice('max_features',[\"log2\", \"sqrt\"]),\n",
    "              \"min_samples_leaf\": 1 + hp.randint('min_samples_leaf', 50-2),\n",
    "              \"criterion\": hp.choice('criterion',[\"entropy\",\"gini\"]),\n",
    "              \"class_weight\":hp.choice('class_weight', ['balanced']),\n",
    "              \"max_leaf_nodes\":2 + hp.randint('max_leaf_nodes', 50-2),\n",
    "               \"min_samples_split\":2 + hp.randint('min_samples_split', 425-250),\n",
    "               \"n_estimators\":100 + hp.randint('n_estimators', 200-1)\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(params, X, y):\n",
    "    \n",
    "    # Initilize instance of estimator\n",
    "    est = RandomForestClassifier(n_jobs = -1)\n",
    "        \n",
    "    # Set params\n",
    "    est.set_params(**params)\n",
    "    \n",
    "    # Calc CV score\n",
    "    scores = cross_val_score(estimator=est, X=X, y=y, \n",
    "                             scoring='roc_auc', cv=5)\n",
    "    score = np.mean(scores)\n",
    "\n",
    "    return score\n",
    "hyperopt_objective = lambda params: (-1.0) * evaluate(params, trainx_outer,trainy_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "# Set algoritm parameters\n",
    "algoo = partial(tpe.suggest,n_startup_jobs=30, gamma=0.25, n_EI_candidates=10)\n",
    "best_vals = fmin(hyperopt_objective, space=para_BS,algo=algoo, max_evals=100, \n",
    "                 trials=trials,rstate=np.random.RandomState(45))\n",
    "# Print best parameters\n",
    "best_params = space_eval(para_BS, best_vals)\n",
    "print(\"BEST PARAMETERS: \" + str(best_params))\n",
    "est = RandomForestClassifier()\n",
    "# Print best CV score\n",
    "scores = [-trial['result']['loss'] for trial in trials.trials]\n",
    "print(\"BEST CV SCORE: \" + str(np.max(scores)))\n",
    "# Set params\n",
    "est.set_params(**best_params)\n",
    "\n",
    "# Fit    \n",
    "est.fit(trainx_outer,trainy_outer)\n",
    "predd = est.predict(testx_outer)\n",
    "test_score = roc_auc_score(testy_outer,predd)\n",
    "\n",
    "print(\"R2 SCORE ON TEST DATA: {}\".format(test_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "19% -0.8336179800394629\n",
    "34% -0.8352200577703162\n",
    "47% -0.8356503116863347\n",
    "BEST PARAMETERS: {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 25, 'max_features': 'log2', 'max_leaf_nodes': 48, 'min_samples_leaf': 34, 'min_samples_split': 55, 'n_estimators': 275}\n",
    "BEST CV SCORE: 0.8357239368369462\n",
    "R2 SCORE ON TEST DATA: 0.7559058496116055\n",
    "    \n",
    "6620679516127401\n",
    "BEST PARAMETERS: {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 27, 'max_features': 'sqrt', 'max_leaf_nodes': 46, 'min_samples_leaf': 35}\n",
    "BEST CV SCORE: 0.6623442968540632\n",
    "R2 SCORE ON TEST DATA: 0.6209965234488746\n",
    "\n",
    "BEST PARAMETERS: {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 38, 'max_features': 'sqrt', 'max_leaf_nodes': 49, 'min_samples_leaf': 34}\n",
    "BEST CV SCORE: 0.6608030017484148\n",
    "R2 SCORE ON TEST DATA: 0.6164814407265441\n",
    "    \n",
    "BEST BEST PARAMETERS: {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 16, 'max_features': 'sqrt', 'max_leaf_nodes': 48, 'min_samples_leaf': 44}\n",
    "BEST CV SCORE: 0.6555040384750981\n",
    "R2 SCORE ON TEST DATA: 0.6245669846241889\n",
    "    \n",
    "    PARAMETERS: {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 29, 'max_features': 'sqrt', 'max_leaf_nodes': 48, 'min_samples_leaf': 13}\n",
    "BEST CV SCORE: 0.6638825006679148\n",
    "R2 SCORE ON TEST DATA: 0.6276915624496116\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = rs_handle.predict(test.loc[:,\"var_0\":\"var_199\"])\n",
    "lgb_pred = pd.DataFrame(columns=[\"target\"],data=pre)\n",
    "print(\"sss\",lgb_pred.groupby(\"target\").count())\n",
    "output = pd.concat([test[\"ID_code\"],lgb_pred], axis = 1)\n",
    "output.to_csv(\"C:/Machine Learning/Hackathons\\Kaggle/Santander Customer Transaction Prediction/outputdt_lr_2.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random Forest parameters _ Random_Search:\n",
    "  'best_score_': 0.8241317748465755,\n",
    "  'best_params_': {'class_weight': 'balanced',\n",
    "   'criterion': 'gini',\n",
    "   'max_depth': 8,\n",
    "   'max_features': 'log2',\n",
    "   'max_leaf_nodes': 23,\n",
    "   'min_impurity_decrease': 0,\n",
    "   'min_samples_leaf': 28,\n",
    "   'min_samples_split': 270,\n",
    "   'n_estimators': 147},\n",
    "  'test_score': 0.7457020336560527,\n",
    "  'time to execute': 10098.947732448578}]\n",
    "    \n",
    "    'best_score_': 0.8271022114605748,\n",
    "  'best_params_': {'class_weight': 'balanced',\n",
    "   'criterion': 'gini',\n",
    "   'max_depth': 8,\n",
    "   'max_features': 'log2',\n",
    "   'max_leaf_nodes': 23,\n",
    "   'min_impurity_decrease': 0,\n",
    "   'min_samples_leaf': 28,\n",
    "   'min_samples_split': 270,\n",
    "   'n_estimators': 184},\n",
    "  'test_score': 0.7483356562247592,\n",
    "  'time to execute': 23570.669979810715}]\n",
    "    \n",
    "RF_hyperopt:\n",
    "     PARAMETERS: {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 25, 'max_features': 'log2', \n",
    "                  'max_leaf_nodes': 48, 'min_samples_leaf': 34, 'min_samples_split': 55, 'n_estimators': 275}\n",
    "BEST CV SCORE: 0.8357239368369462\n",
    "R2 SCORE ON TEST DATA: 0.7559058496116055\n",
    "    \n",
    "extra tree:\n",
    "    \n",
    "    'best_score_': 0.8658975345470915,\n",
    "  'best_params_': {'class_weight': 'balanced',\n",
    "   'criterion': 'gini',\n",
    "   'max_depth': 6,\n",
    "   'max_features': 'log2',\n",
    "   'max_leaf_nodes': 29,\n",
    "   'min_impurity_decrease': 0,\n",
    "   'min_samples_leaf': 18,\n",
    "   'min_samples_split': 416,\n",
    "   'n_estimators': 287},\n",
    "  'test_score': 0.7865753445378643,\n",
    "  'time to execute': 7056.114369153976}]\n",
    "    \n",
    "adaboost:\n",
    "    'best_score_': 0.8666102792803959,\n",
    "  'best_params_': {'algorithm': 'SAMME.R',\n",
    "   'base_estimator__class_weight': 'balanced',\n",
    "   'base_estimator__criterion': 'gini',\n",
    "   'base_estimator__max_depth': 1,\n",
    "   'base_estimator__max_features': 'log2',\n",
    "   'base_estimator__max_leaf_nodes': 11,\n",
    "   'base_estimator__min_impurity_decrease': 0,\n",
    "   'base_estimator__min_samples_leaf': 27,\n",
    "   'base_estimator__min_samples_split': 392,\n",
    "   'n_estimators': 186},\n",
    "  'test_score': 0.7880495302578274,\n",
    "  'time to execute': 21329.237000226974}]\n",
    "    \n",
    "    'best_score_': 0.8556032894558397,\n",
    "  'best_params_': {'algorithm': 'SAMME.R',\n",
    "   'base_estimator__class_weight': 'balanced',\n",
    "   'base_estimator__criterion': 'entropy',\n",
    "   'base_estimator__max_depth': 2,\n",
    "   'base_estimator__max_features': 'sqrt',\n",
    "   'base_estimator__max_leaf_nodes': 17,\n",
    "   'base_estimator__min_impurity_decrease': 0.001,\n",
    "   'base_estimator__min_samples_leaf': 26,\n",
    "   'base_estimator__min_samples_split': 407,\n",
    "   'n_estimators': 137},\n",
    "  'test_score': 0.7780267779186958,\n",
    "  'time to execute': 7897.698915481567}]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_Performance =[]\n",
    "#for train_index , test_index in skf.split(train.loc[:,\"var_0\":\"var_199\"], train[\"target\"]):\n",
    "trainx_outer, testx_outer,trainy_outer, testy_outer = train_test_split(train.loc[:,\"var_0\":\"var_199\"],\n",
    "                                                                       train[\"target\"],test_size=0.30,random_state =10,\n",
    "                                                                       stratify = train[\"target\"])\n",
    "model_perf = {}\n",
    "#trainx_outer, testx_outer = train.loc[:,\"var_0\":\"var_199\"].loc[train_index], train.loc[:,\"var_0\":\"var_199\"].loc[test_index]\n",
    "#trainy_outer, testy_outer = train[\"target\"].loc[train_index], train[\"target\"].loc[test_index]\n",
    "print(trainx_outer.shape, testx_outer.shape, testy_outer.shape, testy_outer.shape)\n",
    "gs= RandomizedSearchCV(estimator=dt, cv=5, param_distributions=para_RS,\n",
    "                       n_jobs=4,n_iter =30, scoring=\"roc_auc\",return_train_score=True)\n",
    "gs.fit(trainx_outer,trainy_outer)\n",
    "pre = gs.predict(testx_outer)\n",
    "test_score = roc_auc_score(testy_outer,pre)\n",
    "model_perf.update({\"best_estimator_\":gs.best_estimator_})\n",
    "model_perf.update({\"best_score_\" : gs.best_score_})\n",
    "model_perf.update({\"best_params_\" : gs.best_params_})\n",
    "model_perf.update({\"test_score\" :   test_score})\n",
    "#model_perf.update({\"gs.cv_results_\" : gs.cv_results_})\n",
    "\n",
    "model_Performance.append(model_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=2,shuffle=True,random_state=10)\n",
    "dt = DecisionTreeClassifier()\n",
    "model_Performance =[]\n",
    "for train_index , test_index in skf.split(train.loc[:,\"var_0\":\"var_199\"], train[\"target\"]):\n",
    "    model_perf = {}\n",
    "    trainx_outer, testx_outer = train.loc[:,\"var_0\":\"var_199\"].loc[train_index], train.loc[:,\"var_0\":\"var_199\"].loc[test_index]\n",
    "    trainy_outer, testy_outer = train[\"target\"].loc[train_index], train[\"target\"].loc[test_index]\n",
    "    print(trainx_outer.shape, testx_outer.shape, testy_outer.shape, testy_outer.shape)\n",
    "    gs= GridSearchCV(estimator=dt, cv=5, param_grid=para,n_jobs=4, scoring=\"roc_auc\",return_train_score=True)\n",
    "    gs.fit(trainx_outer,trainy_outer)\n",
    "    pre = gs.predict(testx_outer)\n",
    "    test_score = roc_auc_score(testy_outer,pre)\n",
    "    model_perf.update({\"best_estimator_\":gs.best_estimator_})\n",
    "    model_perf.update({\"best_score_\" : gs.best_score_})\n",
    "    model_perf.update({\"best_params_\" : gs.best_params_})\n",
    "    model_perf.update({\"test_score\" :   test_score})\n",
    "    #model_perf.update({\"gs.cv_results_\" : gs.cv_results_})\n",
    "    \n",
    "    model_Performance.append(model_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtt = DecisionTreeClassifier()\n",
    "gss= GridSearchCV(estimator=dtt, cv=5, param_grid=para,n_jobs=4, scoring=\"roc_auc\",return_train_score=True)\n",
    "gss.fit(train.loc[:,\"var_0\":\"var_199\"], train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx_outer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=5,max_features=\"sqrt\")\n",
    "dt.fit(train.loc[:,\"var_0\":\"var_199\"], train[\"target\"])\n",
    "dt_predict = dt.predict(X=test.loc[:,\"var_0\":\"var_199\"])\n",
    "df_predict = pd.DataFrame(columns=[\"target\"],data=dt_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000,max_depth=5,max_features=\"sqrt\")\n",
    "rf.fit(train.loc[:,\"var_0\":\"var_199\"], train[\"target\"])\n",
    "rf_predict = rf.predict(X=test.loc[:,\"var_0\":\"var_199\"])\n",
    "rf_predict = pd.DataFrame(columns=[\"target\"],data=rf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = AdaBoostClassifier(n_estimators=1000,learning_rate=.001)\n",
    "ab.fit(train.loc[:,\"var_0\":\"var_199\"], train[\"target\"])\n",
    "ab_predict = ab.predict(X=test.loc[:,\"var_0\":\"var_199\"])\n",
    "ab_predict = pd.DataFrame(columns=[\"target\"],data=ab_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=1000,max_depth=5,max_features=\"sqrt\",learning_rate=.001)\n",
    "gb.fit(train.loc[:,\"var_0\":\"var_199\"], train[\"target\"])\n",
    "gb_predict = gb.predict_proba(X=test.loc[:,\"var_0\":\"var_199\"])\n",
    "gb_predict = pd.DataFrame(columns=[\"target\"],data=gb_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "        learning_rate=0.03534312746092663, max_depth=4,\n",
    "        min_child_samples=200, min_child_weight=0.001, min_split_gain=0.0,\n",
    "        n_estimators=1500, n_iter=10, n_jobs=-1, num_leaves=256,\n",
    "        objective='binary', random_state=10, reg_alpha=0.0, reg_lambda=0.0,\n",
    "        silent=True, subsample=1.0, subsample_for_bin=55934,\n",
    "        subsample_freq=0)\n",
    "#lgb = LGBMClassifier(n_estimators=1000,max_depth=7,learning_rate=.001,eval_metric = \"roc_auc_score\"\n",
    "#                    ,boosting_type =\"goss\")\n",
    "lgb.fit(train.loc[:,\"var_0\":\"var_199\"], train[\"target\"],eval_metric=\"roc_auc_score\",)\n",
    "lgb_predict = lgb.predict_proba(X=test.loc[:,\"var_0\":\"var_199\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = gs.predict(test.loc[:,\"var_0\":\"var_199\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_pred = pd.DataFrame(columns=[\"0\",\"1\"],data=lgb_predict)\n",
    "lgb_pred[\"target\"] = 0\n",
    "lgb_pred.loc[lgb_pred[\"0\"] < .5,\"target\"] = 1\n",
    "print(lgb_pred.groupby(\"target\").count())\n",
    "output = pd.concat([test[\"ID_code\"],lgb_pred], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "             0       1\n",
    "target                \n",
    "0       195389  195389\n",
    "1         4611    4611\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"C:/Machine Learning/Hackathons\\Kaggle/Santander Customer Transaction Prediction/outputdt.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = gs.predict(test.loc[:,\"var_0\":\"var_199\"])\n",
    "lgb_pred = pd.DataFrame(columns=[\"target\"],data=pre)\n",
    "print(\"sss\",lgb_pred.groupby(\"target\").count())\n",
    "output = pd.concat([test[\"ID_code\"],lgb_pred], axis = 1)\n",
    "output.to_csv(\"C:/Machine Learning/Hackathons\\Kaggle/Santander Customer Transaction Prediction/outputdt.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
