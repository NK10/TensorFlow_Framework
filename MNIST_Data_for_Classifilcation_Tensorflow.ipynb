{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import struct\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 128\n",
    "n_epochs = 300\n",
    "n_train = 60000\n",
    "n_test = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    #Download and unzip the dataset mnist if it's not already downloaded \n",
    "    #Download from http://yann.lecun.com/exdb/mnist\n",
    "    mnist_folder = \"C:\\\\Users\\\\USX28939\\\\PYTHON_CODE_BASE\\\\GitHub_Doc\\\\stanford-tensorflow-tutorials\\\\examples\\\\data\\\\MNST_DATA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_one_file(download_url, \n",
    "                    local_dest, \n",
    "                    expected_byte=None, \n",
    "                    unzip_and_remove=False):\n",
    "    \"\"\" \n",
    "    Download the file from download_url into local_dest\n",
    "    if the file doesn't already exists.\n",
    "    If expected_byte is provided, check if \n",
    "    the downloaded file has the same number of bytes.\n",
    "    If unzip_and_remove is True, unzip the file and remove the zip file\n",
    "    \"\"\"\n",
    "    if os.path.exists(local_dest) or os.path.exists(local_dest[:-3]):\n",
    "        print('%s already exists' %local_dest)\n",
    "    else:\n",
    "        print('Downloading %s' %download_url)\n",
    "        local_file, headers = urllib.request.urlretrieve(download_url, local_dest)\n",
    "        file_stat = os.stat(local_dest)\n",
    "        if expected_byte:\n",
    "            if file_stat.st_size == expected_byte:\n",
    "                print('Successfully downloaded %s' %local_dest)\n",
    "                if unzip_and_remove:\n",
    "                    with gzip.open(local_dest, 'rb') as f_in, open(local_dest[:-3],'wb') as f_out:\n",
    "                        shutil.copyfileobj(f_in, f_out)\n",
    "                    os.remove(local_dest)\n",
    "            else:\n",
    "                print('The downloaded file has unexpected number of bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-35-d986ab718bac>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-35-d986ab718bac>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    print (urllib.request.urlopen(\"http://yann.lecun.com/exdb/mnist\\\"))\u001b[0m\n\u001b[1;37m                                                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "print (urllib.request.urlopen(\"http://yann.lecun.com/exdb/mnist\\\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_mnist(path):\n",
    "    \"\"\" \n",
    "    Download and unzip the dataset mnist if it's not already downloaded \n",
    "    Download from http://yann.lecun.com/exdb/mnist\n",
    "    \"\"\"\n",
    "    os.mkdir(path)\n",
    "    url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    filenames = ['train-images-idx3-ubyte.gz',\n",
    "                'train-labels-idx1-ubyte.gz',\n",
    "                't10k-images-idx3-ubyte.gz',\n",
    "                't10k-labels-idx1-ubyte.gz']\n",
    "    expected_bytes = [9912422, 28881, 1648877, 4542]\n",
    "\n",
    "    for filename, byte in zip(filenames, expected_bytes):\n",
    "        download_url = os.path.join(url, filename)\n",
    "        local_dest = os.path.join(path, filename)\n",
    "        print(download_url,\"    -> \", local_dest)\n",
    "        download_one_file(download_url, local_dest, byte, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz     ->  C:\\Users\\USX28939\\PYTHON_CODE_BASE\\GitHub_Doc\\stanford-tensorflow-tutorials\\examples\\data\\MNST_DATA\\train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded C:\\Users\\USX28939\\PYTHON_CODE_BASE\\GitHub_Doc\\stanford-tensorflow-tutorials\\examples\\data\\MNST_DATA\\train-images-idx3-ubyte.gz\n",
      "http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz     ->  C:\\Users\\USX28939\\PYTHON_CODE_BASE\\GitHub_Doc\\stanford-tensorflow-tutorials\\examples\\data\\MNST_DATA\\train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded C:\\Users\\USX28939\\PYTHON_CODE_BASE\\GitHub_Doc\\stanford-tensorflow-tutorials\\examples\\data\\MNST_DATA\\train-labels-idx1-ubyte.gz\n",
      "http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz     ->  C:\\Users\\USX28939\\PYTHON_CODE_BASE\\GitHub_Doc\\stanford-tensorflow-tutorials\\examples\\data\\MNST_DATA\\t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded C:\\Users\\USX28939\\PYTHON_CODE_BASE\\GitHub_Doc\\stanford-tensorflow-tutorials\\examples\\data\\MNST_DATA\\t10k-images-idx3-ubyte.gz\n",
      "http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz     ->  C:\\Users\\USX28939\\PYTHON_CODE_BASE\\GitHub_Doc\\stanford-tensorflow-tutorials\\examples\\data\\MNST_DATA\\t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Successfully downloaded C:\\Users\\USX28939\\PYTHON_CODE_BASE\\GitHub_Doc\\stanford-tensorflow-tutorials\\examples\\data\\MNST_DATA\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "download_mnist(mnist_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_data(path, dataset, flatten):\n",
    "    if dataset != 'train' and dataset != 't10k':\n",
    "        raise NameError('dataset must be train or t10k')\n",
    "\n",
    "    label_file = os.path.join(path, dataset + '-labels-idx1-ubyte')\n",
    "    #print(label_file )\n",
    "    with open(label_file, 'rb') as file:\n",
    "        _, num = struct.unpack(\">II\", file.read(8))\n",
    "        labels = np.fromfile(file, dtype=np.int8) #int8\n",
    "        new_labels = np.zeros((num, 10))\n",
    "        new_labels[np.arange(num), labels] = 1\n",
    "    \n",
    "    img_file = os.path.join(path, dataset + '-images-idx3-ubyte')\n",
    "    with open(img_file, 'rb') as file:\n",
    "        _, num, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "        imgs = np.fromfile(file, dtype=np.uint8).reshape(num, rows, cols) #uint8\n",
    "        imgs = imgs.astype(np.float32) / 255.0\n",
    "        if flatten:\n",
    "            imgs = imgs.reshape([num, -1])\n",
    "\n",
    "    return imgs, new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_mnist(path, flatten=True, num_train=55000):\n",
    "    \"\"\"\n",
    "    Read in the mnist dataset, given that the data is stored in path\n",
    "    Return two tuples of numpy arrays\n",
    "    ((train_imgs, train_labels), (test_imgs, test_labels))\n",
    "    \"\"\"\n",
    "    imgs, labels = parse_data(path, 'train', flatten)\n",
    "    indices = np.random.permutation(labels.shape[0])\n",
    "    train_idx, val_idx = indices[:num_train], indices[num_train:]\n",
    "    train_img, train_labels = imgs[train_idx, :], labels[train_idx, :]\n",
    "    val_img, val_labels = imgs[val_idx, :], labels[val_idx, :]\n",
    "    test = parse_data(path, 't10k', flatten)\n",
    "    return (train_img, train_labels), (val_img, val_labels), test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, val, test = read_mnist(mnist_folder, flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(val))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices(train)\n",
    "train_data = train_data.shuffle(10000) # if you want to shuffle your data\n",
    "train_data = train_data.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = tf.data.Dataset.from_tensor_slices(test)\n",
    "test_data = test_data.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((?, 784), (?, 10)), types: (tf.float32, tf.float64)>\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tf.float32, tf.float64)\n",
      "(TensorShape([Dimension(None), Dimension(784)]), TensorShape([Dimension(None), Dimension(10)]))\n"
     ]
    }
   ],
   "source": [
    "print(train_data.output_types)\n",
    "print(train_data.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterator = tf.data.Iterator.from_structure(train_data.output_types,train_data.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img, label = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"IteratorGetNext:1\", shape=(?, 10), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_init = iterator.make_initializer(train_data)\n",
    "test_init = iterator.make_initializer(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.get_variable(name = \"Weights\", dtype = tf.float32, shape = (784,10), initializer = tf.random_normal_initializer(mean=0.0,\n",
    "    stddev=1.0,seed=None,dtype=tf.float32))\n",
    "b = tf.get_variable(name = \"Bias\", dtype = tf.float32, shape = (1,1) , initializer = tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = tf.matmul(img,w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entropy = tf.nn.softmax_cross_entropy_with_logits(labels=label, logits=logits)\n",
    "loss = tf.reduce_mean(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss epoch 0: 1.554530300373255\n",
      "Average loss epoch 1: 0.5282711567227231\n",
      "Average loss epoch 2: 0.43645217144905135\n",
      "Average loss epoch 3: 0.3905182211898094\n",
      "Average loss epoch 4: 0.35706941920310953\n",
      "Average loss epoch 5: 0.3416221655558708\n",
      "Average loss epoch 6: 0.32569807908216186\n",
      "Average loss epoch 7: 0.3159015924778096\n",
      "Average loss epoch 8: 0.3114186773639779\n",
      "Average loss epoch 9: 0.3054083053975604\n",
      "Average loss epoch 10: 0.29594300061810846\n",
      "Average loss epoch 11: 0.29552561398162397\n",
      "Average loss epoch 12: 0.2907459866168887\n",
      "Average loss epoch 13: 0.2848046081877032\n",
      "Average loss epoch 14: 0.28220534555094184\n",
      "Average loss epoch 15: 0.28202645170480706\n",
      "Average loss epoch 16: 0.2779443462920743\n",
      "Average loss epoch 17: 0.27451884294318596\n",
      "Average loss epoch 18: 0.2747225878197093\n",
      "Average loss epoch 19: 0.2780618068090705\n",
      "Average loss epoch 20: 0.272434873081917\n",
      "Average loss epoch 21: 0.2704527992148732\n",
      "Average loss epoch 22: 0.26743023327963295\n",
      "Average loss epoch 23: 0.26881863426330477\n",
      "Average loss epoch 24: 0.26825650713818017\n",
      "Average loss epoch 25: 0.2675402584117512\n",
      "Average loss epoch 26: 0.2674353941235431\n",
      "Average loss epoch 27: 0.2664662902091825\n",
      "Average loss epoch 28: 0.2655478720574878\n",
      "Average loss epoch 29: 0.26494288763334584\n",
      "Average loss epoch 30: 0.2634468232303165\n",
      "Average loss epoch 31: 0.2636421054255131\n",
      "Average loss epoch 32: 0.2613870157058849\n",
      "Average loss epoch 33: 0.2611775212682957\n",
      "Average loss epoch 34: 0.2614073318104411\n",
      "Average loss epoch 35: 0.26342518944726434\n",
      "Average loss epoch 36: 0.26073084229300186\n",
      "Average loss epoch 37: 0.2605749956223854\n",
      "Average loss epoch 38: 0.25914974772306376\n",
      "Average loss epoch 39: 0.26221003892809847\n",
      "Average loss epoch 40: 0.2605952109535073\n",
      "Average loss epoch 41: 0.259735012643559\n",
      "Average loss epoch 42: 0.2591307424355385\n",
      "Average loss epoch 43: 0.26086105813467225\n",
      "Average loss epoch 44: 0.2603577319445998\n",
      "Average loss epoch 45: 0.2584113195018713\n",
      "Average loss epoch 46: 0.25761625841259955\n",
      "Average loss epoch 47: 0.2572609363426996\n",
      "Average loss epoch 48: 0.258890383084153\n",
      "Average loss epoch 49: 0.25666824626021606\n",
      "Average loss epoch 50: 0.25668437657661214\n",
      "Average loss epoch 51: 0.25877507689387297\n",
      "Average loss epoch 52: 0.25760337464338123\n",
      "Average loss epoch 53: 0.2561324836209763\n",
      "Average loss epoch 54: 0.2591450346417205\n",
      "Average loss epoch 55: 0.25797788636802244\n",
      "Average loss epoch 56: 0.2562756297200225\n",
      "Average loss epoch 57: 0.25692848244378735\n",
      "Average loss epoch 58: 0.25727581910269204\n",
      "Average loss epoch 59: 0.2547946678864401\n",
      "Average loss epoch 60: 0.25665901983373385\n",
      "Average loss epoch 61: 0.25591506072601605\n",
      "Average loss epoch 62: 0.25517176582023154\n",
      "Average loss epoch 63: 0.2548181278934312\n",
      "Average loss epoch 64: 0.25607760763445564\n",
      "Average loss epoch 65: 0.2550103371573049\n",
      "Average loss epoch 66: 0.2567167157177315\n",
      "Average loss epoch 67: 0.2543881645556106\n",
      "Average loss epoch 68: 0.25627422350090606\n",
      "Average loss epoch 69: 0.25559474822393685\n",
      "Average loss epoch 70: 0.2550615152647329\n",
      "Average loss epoch 71: 0.25497204080917113\n",
      "Average loss epoch 72: 0.25373326247168143\n",
      "Average loss epoch 73: 0.2554169850813788\n",
      "Average loss epoch 74: 0.253288188143525\n",
      "Average loss epoch 75: 0.25564665777045625\n",
      "Average loss epoch 76: 0.25559278575833455\n",
      "Average loss epoch 77: 0.2505437508225441\n",
      "Average loss epoch 78: 0.25502723290823226\n",
      "Average loss epoch 79: 0.2537380602124125\n",
      "Average loss epoch 80: 0.25397026805683626\n",
      "Average loss epoch 81: 0.2547900884303936\n",
      "Average loss epoch 82: 0.2547740147730639\n",
      "Average loss epoch 83: 0.2535717336071092\n",
      "Average loss epoch 84: 0.2557253781446191\n",
      "Average loss epoch 85: 0.2532582220643066\n",
      "Average loss epoch 86: 0.2543599438182143\n",
      "Average loss epoch 87: 0.25367682439296746\n",
      "Average loss epoch 88: 0.2541154065797495\n",
      "Average loss epoch 89: 0.25342958948986477\n",
      "Average loss epoch 90: 0.253007125776521\n",
      "Average loss epoch 91: 0.25264762717970585\n",
      "Average loss epoch 92: 0.2517184818033562\n",
      "Average loss epoch 93: 0.25297053482296855\n",
      "Average loss epoch 94: 0.25290928651080574\n",
      "Average loss epoch 95: 0.2538208286256291\n",
      "Average loss epoch 96: 0.25167611399015716\n",
      "Average loss epoch 97: 0.2551033801637417\n",
      "Average loss epoch 98: 0.25334741346711337\n",
      "Average loss epoch 99: 0.25212285411219265\n",
      "Average loss epoch 100: 0.2542253473297108\n",
      "Average loss epoch 101: 0.25094538499103036\n",
      "Average loss epoch 102: 0.25307736525008845\n",
      "Average loss epoch 103: 0.25078210439099824\n",
      "Average loss epoch 104: 0.252937651945408\n",
      "Average loss epoch 105: 0.2514133022448351\n",
      "Average loss epoch 106: 0.2554778600674729\n",
      "Average loss epoch 107: 0.2527227209231188\n",
      "Average loss epoch 108: 0.25112005827385325\n",
      "Average loss epoch 109: 0.2555594638509806\n",
      "Average loss epoch 110: 0.25237531786741213\n",
      "Average loss epoch 111: 0.25311728911690934\n",
      "Average loss epoch 112: 0.25407753668205685\n",
      "Average loss epoch 113: 0.2515015331984952\n",
      "Average loss epoch 114: 0.2549517600862093\n",
      "Average loss epoch 115: 0.2543924510998781\n",
      "Average loss epoch 116: 0.25048178553927775\n",
      "Average loss epoch 117: 0.25063093760332394\n",
      "Average loss epoch 118: 0.2514346397200296\n",
      "Average loss epoch 119: 0.2553674960292356\n",
      "Average loss epoch 120: 0.2507736076189335\n",
      "Average loss epoch 121: 0.2534111231912014\n",
      "Average loss epoch 122: 0.25165274713275043\n",
      "Average loss epoch 123: 0.2522356985613357\n",
      "Average loss epoch 124: 0.2505626224327919\n",
      "Average loss epoch 125: 0.25333361306855845\n",
      "Average loss epoch 126: 0.2493870526898739\n",
      "Average loss epoch 127: 0.2535051359080298\n",
      "Average loss epoch 128: 0.25332560813011124\n",
      "Average loss epoch 129: 0.25304569836792556\n",
      "Average loss epoch 130: 0.2521018782154072\n",
      "Average loss epoch 131: 0.25356513237537337\n",
      "Average loss epoch 132: 0.25412958747772285\n",
      "Average loss epoch 133: 0.25514145668509397\n",
      "Average loss epoch 134: 0.25281053187195646\n",
      "Average loss epoch 135: 0.2539003057275401\n",
      "Average loss epoch 136: 0.25088540306964585\n",
      "Average loss epoch 137: 0.24953803893958412\n",
      "Average loss epoch 138: 0.2537005458720202\n",
      "Average loss epoch 139: 0.2520208525276461\n",
      "Average loss epoch 140: 0.25050250601976415\n",
      "Average loss epoch 141: 0.2533914296606252\n",
      "Average loss epoch 142: 0.2518519658855228\n",
      "Average loss epoch 143: 0.25314657923787137\n",
      "Average loss epoch 144: 0.25196716755975124\n",
      "Average loss epoch 145: 0.25188104198422545\n",
      "Average loss epoch 146: 0.2520383851299452\n",
      "Average loss epoch 147: 0.25012493778106776\n",
      "Average loss epoch 148: 0.25381716695982354\n",
      "Average loss epoch 149: 0.2520081888104594\n",
      "Average loss epoch 150: 0.2533280955844147\n",
      "Average loss epoch 151: 0.25421679127354957\n",
      "Average loss epoch 152: 0.2514948134158933\n",
      "Average loss epoch 153: 0.2529799436413965\n",
      "Average loss epoch 154: 0.25003735790419024\n",
      "Average loss epoch 155: 0.2507203487809314\n",
      "Average loss epoch 156: 0.25413459584463477\n",
      "Average loss epoch 157: 0.2526811143253432\n",
      "Average loss epoch 158: 0.25214265557222587\n",
      "Average loss epoch 159: 0.2517972317892452\n",
      "Average loss epoch 160: 0.25038803909407104\n",
      "Average loss epoch 161: 0.2516593990804151\n",
      "Average loss epoch 162: 0.2520450050401133\n",
      "Average loss epoch 163: 0.25040269272271976\n",
      "Average loss epoch 164: 0.25133603825125583\n",
      "Average loss epoch 165: 0.25125261664737103\n",
      "Average loss epoch 166: 0.25162722669368565\n",
      "Average loss epoch 167: 0.24930801579598771\n",
      "Average loss epoch 168: 0.25272368802580725\n",
      "Average loss epoch 169: 0.25009634621268095\n",
      "Average loss epoch 170: 0.2534063754213411\n",
      "Average loss epoch 171: 0.24992006587427715\n",
      "Average loss epoch 172: 0.25147380472788977\n",
      "Average loss epoch 173: 0.2502887853356295\n",
      "Average loss epoch 174: 0.25011479840722195\n",
      "Average loss epoch 175: 0.2516159638415935\n",
      "Average loss epoch 176: 0.25170946157602375\n",
      "Average loss epoch 177: 0.24799049030556236\n",
      "Average loss epoch 178: 0.24958628805917363\n",
      "Average loss epoch 179: 0.2520435412782569\n",
      "Average loss epoch 180: 0.24896575874367424\n",
      "Average loss epoch 181: 0.2511252845269303\n",
      "Average loss epoch 182: 0.2537869508876357\n",
      "Average loss epoch 183: 0.2508772690975389\n",
      "Average loss epoch 184: 0.25220511851962224\n",
      "Average loss epoch 185: 0.25196722834262736\n",
      "Average loss epoch 186: 0.2532809608897498\n",
      "Average loss epoch 187: 0.2504517764892689\n",
      "Average loss epoch 188: 0.25228170064646144\n",
      "Average loss epoch 189: 0.2494755673720393\n",
      "Average loss epoch 190: 0.2517879562495753\n",
      "Average loss epoch 191: 0.24984652633930363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss epoch 192: 0.24971406846198924\n",
      "Average loss epoch 193: 0.2501825309250244\n",
      "Average loss epoch 194: 0.2519724912421648\n",
      "Average loss epoch 195: 0.25415506071822586\n",
      "Average loss epoch 196: 0.2489087585619716\n",
      "Average loss epoch 197: 0.2500771059719629\n",
      "Average loss epoch 198: 0.2481186149598554\n",
      "Average loss epoch 199: 0.2505466312343298\n",
      "Average loss epoch 200: 0.2501477397631767\n",
      "Average loss epoch 201: 0.2502559124383815\n",
      "Average loss epoch 202: 0.24885101969852003\n",
      "Average loss epoch 203: 0.2520024551901706\n",
      "Average loss epoch 204: 0.25073155256551366\n",
      "Average loss epoch 205: 0.2503488183368084\n",
      "Average loss epoch 206: 0.2509632756543714\n",
      "Average loss epoch 207: 0.25173819098015165\n",
      "Average loss epoch 208: 0.24971726023873617\n",
      "Average loss epoch 209: 0.2504715567238109\n",
      "Average loss epoch 210: 0.24932081008026766\n",
      "Average loss epoch 211: 0.25024667612688484\n",
      "Average loss epoch 212: 0.24966542232175207\n",
      "Average loss epoch 213: 0.24914045710723068\n",
      "Average loss epoch 214: 0.25233473576778587\n",
      "Average loss epoch 215: 0.250842768889527\n",
      "Average loss epoch 216: 0.25040326789021494\n",
      "Average loss epoch 217: 0.25147585109915843\n",
      "Average loss epoch 218: 0.25340836573132247\n",
      "Average loss epoch 219: 0.25171427998778434\n",
      "Average loss epoch 220: 0.25115135767778685\n",
      "Average loss epoch 221: 0.24897951818136282\n",
      "Average loss epoch 222: 0.25133313817340275\n",
      "Average loss epoch 223: 0.2507133953446566\n",
      "Average loss epoch 224: 0.2501167410681414\n",
      "Average loss epoch 225: 0.2515647018371626\n",
      "Average loss epoch 226: 0.2508362599930098\n",
      "Average loss epoch 227: 0.2526138186454773\n",
      "Average loss epoch 228: 0.2504128653122935\n",
      "Average loss epoch 229: 0.2504439424983291\n",
      "Average loss epoch 230: 0.25403565029765285\n",
      "Average loss epoch 231: 0.2525486653887255\n",
      "Average loss epoch 232: 0.2520916903434798\n",
      "Average loss epoch 233: 0.2516690629686034\n",
      "Average loss epoch 234: 0.24812356885089432\n",
      "Average loss epoch 235: 0.2522450343294199\n",
      "Average loss epoch 236: 0.24965943489656892\n",
      "Average loss epoch 237: 0.2525197780236255\n",
      "Average loss epoch 238: 0.24942279555076777\n",
      "Average loss epoch 239: 0.25069963297871656\n",
      "Average loss epoch 240: 0.24914506675545559\n",
      "Average loss epoch 241: 0.24970128811722578\n",
      "Average loss epoch 242: 0.2501391095304212\n",
      "Average loss epoch 243: 0.25020923110288246\n",
      "Average loss epoch 244: 0.2496298470815947\n",
      "Average loss epoch 245: 0.2496210209678772\n",
      "Average loss epoch 246: 0.2505182923359233\n",
      "Average loss epoch 247: 0.24959449961261693\n",
      "Average loss epoch 248: 0.2502544932847106\n",
      "Average loss epoch 249: 0.2500611430337263\n",
      "Average loss epoch 250: 0.25185442825042925\n",
      "Average loss epoch 251: 0.2517565538023793\n",
      "Average loss epoch 252: 0.25259326762238216\n",
      "Average loss epoch 253: 0.24899539328938305\n",
      "Average loss epoch 254: 0.2525469109242739\n",
      "Average loss epoch 255: 0.2523930509163197\n",
      "Average loss epoch 256: 0.24937606301418572\n",
      "Average loss epoch 257: 0.251141552280548\n",
      "Average loss epoch 258: 0.24983633030639138\n",
      "Average loss epoch 259: 0.2506688022336295\n",
      "Average loss epoch 260: 0.24944397264788318\n",
      "Average loss epoch 261: 0.24743440508149392\n",
      "Average loss epoch 262: 0.2488595287813697\n",
      "Average loss epoch 263: 0.253495247506125\n",
      "Average loss epoch 264: 0.24991864775155867\n",
      "Average loss epoch 265: 0.2511442040288171\n",
      "Average loss epoch 266: 0.2498304716376371\n",
      "Average loss epoch 267: 0.25182525668033334\n",
      "Average loss epoch 268: 0.24871764829338983\n",
      "Average loss epoch 269: 0.2499364146313002\n",
      "Average loss epoch 270: 0.25038453357857327\n",
      "Average loss epoch 271: 0.250536528333675\n",
      "Average loss epoch 272: 0.25152730844741644\n",
      "Average loss epoch 273: 0.2497037865568039\n",
      "Average loss epoch 274: 0.2520803050419619\n",
      "Average loss epoch 275: 0.2489267426088106\n",
      "Average loss epoch 276: 0.25068172160969227\n",
      "Average loss epoch 277: 0.2484521109350892\n",
      "Average loss epoch 278: 0.25255299607335135\n",
      "Average loss epoch 279: 0.2517133587494839\n",
      "Average loss epoch 280: 0.24740920401243277\n",
      "Average loss epoch 281: 0.24977971979005392\n",
      "Average loss epoch 282: 0.24891983819908875\n",
      "Average loss epoch 283: 0.25142500731487605\n",
      "Average loss epoch 284: 0.24908382073044777\n",
      "Average loss epoch 285: 0.24924167436222697\n",
      "Average loss epoch 286: 0.2503983443559602\n",
      "Average loss epoch 287: 0.2547156581005385\n",
      "Average loss epoch 288: 0.24891912056089835\n",
      "Average loss epoch 289: 0.2486826550648656\n",
      "Average loss epoch 290: 0.2536435447979805\n",
      "Average loss epoch 291: 0.2515391304569189\n",
      "Average loss epoch 292: 0.2511162800151248\n",
      "Average loss epoch 293: 0.24833664686180826\n",
      "Average loss epoch 294: 0.25155151006440785\n",
      "Average loss epoch 295: 0.2527840071985888\n",
      "Average loss epoch 296: 0.24901118214393772\n",
      "Average loss epoch 297: 0.252289669752814\n",
      "Average loss epoch 298: 0.2501328367826551\n",
      "Average loss epoch 299: 0.25129278376698494\n",
      "Total time: 181.16978883743286 seconds\n",
      "Accuracy 0.9124\n"
     ]
    }
   ],
   "source": [
    "preds = tf.nn.softmax(logits)\n",
    "correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(label, 1))\n",
    "accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "\n",
    "writer = tf.summary.FileWriter('C:/Users/USX28939/PYTHON_CODE_BASE/graphs', tf.get_default_graph())\n",
    "# to access the tensorboard graph use tensorboard --logdir training:C:\\path of the log dir\n",
    "# there is no equal sign after the logdir and add any text before the drive as its a bug\n",
    "with tf.Session() as sess:\n",
    "   \n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # train the model n_epochs times\n",
    "    for i in range(n_epochs): \t\n",
    "        sess.run(train_init)\t# drawing samples from train_data\n",
    "        total_loss = 0\n",
    "        n_batches = 0\n",
    "        try:\n",
    "            while True:\n",
    "                _, l = sess.run([optimizer, loss])\n",
    "                total_loss += l\n",
    "                n_batches += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        print('Average loss epoch {0}: {1}'.format(i, total_loss/n_batches))\n",
    "    print('Total time: {0} seconds'.format(time.time() - start_time))\n",
    "\n",
    "    # test the model\n",
    "    sess.run(test_init)\t\t\t# drawing samples from test_data\n",
    "    total_correct_preds = 0\n",
    "    try:\n",
    "        while True:\n",
    "            accuracy_batch = sess.run(accuracy)\n",
    "            total_correct_preds += accuracy_batch\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "\n",
    "    print('Accuracy {0}'.format(total_correct_preds/n_test))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os as os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\USX28939\\\\PYTHON_CODE_BASE\\\\GitHub_Doc\\\\TensorFlow_Framework'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
